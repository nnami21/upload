{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import preprocessing as prep\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pdb\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orc_ARSN        = np.load('dataset/ARSN_oracle.npy', encoding='bytes')\n",
    "orc_ARSN_label  = np.load('dataset/ARSN_oracle_label.npy', encoding='bytes')\n",
    "test_ARSN       = np.load('dataset/ARSN_test.npy', encoding='bytes')\n",
    "test_ARSN_label = np.load('dataset/ARSN_test_label.npy', encoding='bytes')\n",
    "\n",
    "#train_MESS       = np.load('dataset/MESSIDOR_train.npy', encoding='bytes')\n",
    "#train_MESS_label = np.load('dataset/MESSIDOR_train_label.npy', encoding='bytes')\n",
    "#test_MESS        = np.load('dataset/MESSIDOR_test.npy', encoding='bytes')\n",
    "#test_MESS_label  = np.load('dataset/MESSIDOR_test_label.npy', encoding='bytes')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess images\n",
    "orc_ARSN   = np.transpose(orc_ARSN, (0, 3, 1, 2))\n",
    "test_ARSN  = np.transpose(test_ARSN, (0, 3, 1, 2))\n",
    "#train_MESS = np.transpose(train_MESS, (0,3,1,2))\n",
    "#test_MESS  = np.transpose(test_MESS, (0,3,1,2))\n",
    "orc_ARSN_prep, test_ARSN_prep   = prep.clean(orc_ARSN,test_ARSN,512)\n",
    "#train_MESS_prep, test_MESS_prep = prep.clean(train_MESS,test_MESS,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inception model\n",
    "inception = models.inception_v3()\n",
    "\n",
    "# Inception v3 pretrained weights\n",
    "model_dir = '/afs/ece.cmu.edu/usr/sadom/Private/Active_learning/pretrained_model'\n",
    "model_urls = {'inception_v3_google': \n",
    "    'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth',}\n",
    "inception.load_state_dict(model_zoo.load_url(\n",
    "    model_urls['inception_v3_google'],model_dir=model_dir))\n",
    "inception.aux_logits = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Medal(nn.Module):\n",
    "    def __init__(self, pretrain_inception, num_classes):\n",
    "        super(Medal, self).__init__()\n",
    "        self.inception = pretrain_inception\n",
    "        self.linear_0        = nn.Linear(1000, 512)\n",
    "        self.dropout         = nn.Dropout(0.5)\n",
    "        self.linear_1        = nn.Linear(512, 128)\n",
    "        self.linear_2        = nn.Linear(128, num_classes)\n",
    "        self.relu            = nn.ReLU()\n",
    "        self.sigmoid         = nn.Sigmoid()\n",
    "        \n",
    "        self.init_weight()\n",
    "        \n",
    "    def forward(self, images):\n",
    "        out = self.inception(images)\n",
    "        out = self.linear_0(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.linear_1(out))\n",
    "        out = self.linear_2(out)\n",
    "        \n",
    "        return self.sigmoid(out)\n",
    "    \n",
    "    def init_weight(self):\n",
    "        self.linear_0.weight.data.uniform_(-0.1,0.1)\n",
    "        self.linear_1.weight.data.uniform_(-0.1,0.1)\n",
    "        self.linear_2.weight.data.uniform_(-0.1,0.1)\n",
    "        \n",
    "        self.linear_0.bias.data.fill_(0)\n",
    "        self.linear_1.bias.data.fill_(0)\n",
    "        self.linear_2.bias.data.fill_(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedalTrainer:\n",
    "    def __init__(self, model, batch_size, max_epochs=1, path='model.pt'):\n",
    "        global orc_ARSN_prep, orc_ARSN_label, test_ARSN_prep, test_ARSN_label\n",
    "        # feel free to add any other parameters here\n",
    "        self.model      = model\n",
    "        self.batch_size = batch_size\n",
    "        self.orc_ARSN   = orc_ARSN_prep\n",
    "        self.orc_ARSN_label  = orc_ARSN_label\n",
    "        self.test_ARSN       = test_ARSN_prep\n",
    "        self.test_ARSN_label = test_ARSN_label\n",
    "        #self.train_MESS       = train_MESS_prep\n",
    "        #self.train_MESS_label = train_MESS_label\n",
    "        #self.test_MESS        = test_MESS_prep\n",
    "        #self.test_MESS_label  = test_MESS_label\n",
    "        self.train_losses = []\n",
    "        self.test_losses  = []\n",
    "        self.test_acc     = []\n",
    "        self.test_auc_score = []\n",
    "        self.epochs = 0\n",
    "        self.prev_epoch = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.path = path\n",
    "        \n",
    "        # TODO: Define your optimizer and criterion here\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(),lr=0.0001, weight_decay=1e-6)\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train() # set to training mode\n",
    "        epoch_loss = 0\n",
    "        batch_num = 0\n",
    "        index = np.random.choice(orc_ARSN.shape[0], size=(orc_ARSN.shape[0],), replace=False)\n",
    "        for i in range(0, self.orc_ARSN.shape[0]-self.batch_size, self.batch_size):\n",
    "            inputs  = self.orc_ARSN[index[i:i+self.batch_size]]\n",
    "            targets = self.orc_ARSN_label[index[i:i+self.batch_size]]\n",
    "            loss = self.train_batch(inputs, targets)\n",
    "            epoch_loss += loss\n",
    "            batch_num += 1\n",
    "            if batch_num % 10 == 0:\n",
    "                print(\"At batch\",batch_num)\n",
    "                print(\"Loss:\",loss)\n",
    "        epoch_loss = epoch_loss / batch_num\n",
    "        self.epochs += 1\n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "        \n",
    "        return epoch_loss\n",
    "\n",
    "    def train_batch(self, inputs, targets):\n",
    "        inputs  = torch.from_numpy(inputs).to(DEVICE).float()\n",
    "        targets = torch.from_numpy(targets).to(DEVICE).float()\n",
    "        outputs = torch.flatten(self.model(inputs))\n",
    "        loss    = self.criterion(outputs,targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        auc_score = 0\n",
    "        test_acc  = 0\n",
    "        batch_num = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, self.test_ARSN.shape[0], self.batch_size):\n",
    "                inputs  = self.test_ARSN[i:i+self.batch_size]\n",
    "                targets = self.test_ARSN_label[i:i+self.batch_size]\n",
    "                loss, acc, r_sco = self.test_batch(inputs,targets)\n",
    "                test_loss += loss\n",
    "                test_acc  += acc\n",
    "                auc_score += r_sco\n",
    "                batch_num += 1\n",
    "            test_loss /= batch_num\n",
    "            auc_score  = 100* auc_score/batch_num\n",
    "            test_acc   = 100* test_acc/(batch_num*self.batch_size)\n",
    "            \n",
    "            self.test_losses.append(test_loss)\n",
    "            self.test_acc.append(test_acc)\n",
    "            self.test_auc_score.append(auc_score)\n",
    "            print('[Test]  Epoch [%d/%d]   Loss: %.4f Accuracy: %.4f AUC_Score: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, test_loss, test_acc, auc_score))\n",
    "        return test_loss, test_acc, auc_score\n",
    "            \n",
    "    def test_batch(self, inputs, targets):\n",
    "        inputs  = torch.from_numpy(inputs).to(DEVICE).float()\n",
    "        targets = torch.from_numpy(targets).to(DEVICE).float()\n",
    "        outputs = torch.flatten(self.model(inputs))\n",
    "        loss    = self.criterion(outputs,targets) \n",
    "        predicted = torch.round(outputs.data)\n",
    "        correct   = (predicted == targets).sum()\n",
    "        auc_score = roc_auc_score(targets,outputs.data)\n",
    "        \n",
    "        return loss.item(), correct.item(), auc_score\n",
    "        \n",
    "    def load(self):\n",
    "        checkpoint = torch.load(self.path)\n",
    "        self.prev_epoch = checkpoint['epoch']\n",
    "        self.model.load_state_dict(checkpoint['state_dict'])\n",
    "        self.model.cuda()\n",
    "        print(\"Model Loaded!\")\n",
    "        \n",
    "    def save(self):\n",
    "        self.model.cpu()\n",
    "        state = {'epoch': self.epochs+self.prev_epoch, \n",
    "                 'state_dict': self.model.state_dict()}\n",
    "        torch.save(state, self.path)\n",
    "        self.model.cuda()\n",
    "        print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "load_model = True\n",
    "path       = 'model/ARSN_baseline.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "model   = Medal(inception,1)\n",
    "model   = nn.DataParallel(model)\n",
    "model   = model.to(DEVICE)\n",
    "trainer = MedalTrainer(model,BATCH_SIZE, NUM_EPOCHS, path)\n",
    "\n",
    "if load_model:\n",
    "    trainer.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]  Epoch [0/50]   Loss: 3.4615 Accuracy: 64.0625 AUC_Score: 52.2731\n",
      "--Return--\n",
      "> <ipython-input-9-53c07dcbe34c>(2)<module>()->None\n",
      "-> pdb.set_trace()\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-53c07dcbe34c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbest_nll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e30\u001b[0m  \u001b[0;31m# set to super large value at first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'return'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_return\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_returning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;31m# The user issued a 'next' or 'until' command.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoplineno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.test()\n",
    "pdb.set_trace()\n",
    "best_nll = 1e30  # set to super large value at first\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    nll = trainer.train()\n",
    "    if nll < best_nll:\n",
    "        trainer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
